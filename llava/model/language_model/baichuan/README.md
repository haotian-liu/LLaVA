---
language:
  - en
  - zh
license_name: baichuan2-community-license
license_link: https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat/blob/main/Community%20License%20for%20Baichuan2%20Model.pdf
tasks:
  - text-generation
---

<!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->
<div align="center">
<h1>
  Baichuan 2
</h1>
</div>

<div align="center">
<a href="https://github.com/baichuan-inc/Baichuan2" target="_blank">ğŸ¦‰GitHub</a> | <a href="https://github.com/baichuan-inc/Baichuan-7B/blob/main/media/wechat.jpeg?raw=true" target="_blank">ğŸ’¬WeChat</a>
</div>
<div align="center">
  ç™¾å·APIæ”¯æŒæœç´¢å¢å¼ºå’Œ192Ké•¿çª—å£ï¼Œæ–°å¢ç™¾å·æœç´¢å¢å¼ºçŸ¥è¯†åº“ã€é™æ—¶å…è´¹ï¼<br>
ğŸš€ <a href="https://www.baichuan-ai.com/" target="_blank">ç™¾å·å¤§æ¨¡å‹åœ¨çº¿å¯¹è¯å¹³å°</a> å·²æ­£å¼å‘å…¬ä¼—å¼€æ”¾ ğŸ‰
</div>

# ç›®å½•/Table of Contents

- [ğŸ“– æ¨¡å‹ä»‹ç»/Introduction](#Introduction)
- [âš™ï¸ å¿«é€Ÿå¼€å§‹/Quick Start](#Start)
- [ğŸ“Š Benchmarkè¯„ä¼°/Benchmark Evaluation](#Benchmark)
- [ğŸ‘¥ ç¤¾åŒºä¸ç”Ÿæ€/Community](#Community)
- [ğŸ“œ å£°æ˜ä¸åè®®/Terms and Conditions](#Terms)


# <span id="Introduction">æ¨¡å‹ä»‹ç»/Introduction</span>

Baichuan 2 æ˜¯[ç™¾å·æ™ºèƒ½]æ¨å‡ºçš„æ–°ä¸€ä»£å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨ **2.6 ä¸‡äº¿**  Tokens çš„é«˜è´¨é‡è¯­æ–™è®­ç»ƒï¼Œåœ¨æƒå¨çš„ä¸­æ–‡å’Œè‹±æ–‡ benchmark
ä¸Šå‡å–å¾—åŒå°ºå¯¸æœ€å¥½çš„æ•ˆæœã€‚æœ¬æ¬¡å‘å¸ƒåŒ…å«æœ‰ 7Bã€13B çš„ Base å’Œ Chat ç‰ˆæœ¬ï¼Œå¹¶æä¾›äº† Chat ç‰ˆæœ¬çš„ 4bits
é‡åŒ–ï¼Œæ‰€æœ‰ç‰ˆæœ¬ä¸ä»…å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ï¼Œå¼€å‘è€…ä¹Ÿä»…éœ€[é‚®ä»¶ç”³è¯·]å¹¶è·å¾—å®˜æ–¹å•†ç”¨è®¸å¯åï¼Œå³å¯ä»¥å…è´¹å•†ç”¨ã€‚å…·ä½“å‘å¸ƒç‰ˆæœ¬å’Œä¸‹è½½è§ä¸‹è¡¨ï¼š

Baichuan 2 is the new generation of large-scale open-source language models launched by [Baichuan Intelligence inc.](https://www.baichuan-ai.com/). 
It is trained on a high-quality corpus with 2.6 trillion tokens and has achieved the best performance in authoritative Chinese and English benchmarks of the same size. 
This release includes 7B and 13B versions for both Base and Chat models, along with a 4bits quantized version for the Chat model. 
All versions are fully open to academic research, and developers can also use them for free in commercial applications after obtaining an official commercial license through [email request](mailto:opensource@baichuan-inc.com). 
The specific release versions and download links are listed in the table below:

|     |          Base Model        |          Chat Model        |       4bits Quantized Chat Model        |
|:---:|:--------------------:|:--------------------:|:--------------------------:|
| 7B  | [Baichuan2-7B-Base](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base)  | [Baichuan2-7B-Chat](https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat)  | [Baichuan2-7B-Chat-4bits](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base-4bits)  |
| 13B | [Baichuan2-13B-Base](https://huggingface.co/baichuan-inc/Baichuan2-13B-Base) | [Baichuan2-13B-Chat](https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat) | [Baichuan2-13B-Chat-4bits](https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat-4bits) |

# <span id="Start">å¿«é€Ÿå¼€å§‹/Quick Start</span>

åœ¨Baichuan2ç³»åˆ—æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬ä¸ºäº†åŠ å¿«æ¨ç†é€Ÿåº¦ä½¿ç”¨äº†Pytorch2.0åŠ å…¥çš„æ–°åŠŸèƒ½F.scaled_dot_product_attentionï¼Œå› æ­¤æ¨¡å‹éœ€è¦åœ¨Pytorch2.0ç¯å¢ƒä¸‹è¿è¡Œã€‚

In the Baichuan 2 series models, we have utilized the new feature `F.scaled_dot_product_attention` introduced in PyTorch 2.0 to accelerate inference speed. Therefore, the model needs to be run in a PyTorch 2.0 environment.


```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from transformers.generation.utils import GenerationConfig
tokenizer = AutoTokenizer.from_pretrained("baichuan-inc/Baichuan2-7B-Chat", use_fast=False, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-7B-Chat", device_map="auto", torch_dtype=torch.bfloat16, trust_remote_code=True)
model.generation_config = GenerationConfig.from_pretrained("baichuan-inc/Baichuan2-7B-Chat")
messages = []
messages.append({"role": "user", "content": "è§£é‡Šä¸€ä¸‹â€œæ¸©æ•…è€ŒçŸ¥æ–°â€"})
response = model.chat(tokenizer, messages)
print(response)
"æ¸©æ•…è€ŒçŸ¥æ–°"æ˜¯ä¸€å¥ä¸­å›½å¤ä»£çš„æˆè¯­ï¼Œå‡ºè‡ªã€Šè®ºè¯­Â·ä¸ºæ”¿ã€‹ç¯‡ã€‚è¿™å¥è¯çš„æ„æ€æ˜¯ï¼šé€šè¿‡å›é¡¾è¿‡å»ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°æ–°çš„çŸ¥è¯†å’Œç†è§£ã€‚æ¢å¥è¯è¯´ï¼Œå­¦ä¹ å†å²å’Œç»éªŒå¯ä»¥è®©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£ç°åœ¨å’Œæœªæ¥ã€‚

è¿™å¥è¯é¼“åŠ±æˆ‘ä»¬åœ¨å­¦ä¹ å’Œç”Ÿæ´»ä¸­ä¸æ–­åœ°å›é¡¾å’Œåæ€è¿‡å»çš„ç»éªŒï¼Œä»è€Œè·å¾—æ–°çš„å¯ç¤ºå’Œæˆé•¿ã€‚é€šè¿‡é‡æ¸©æ—§çš„çŸ¥è¯†å’Œç»å†ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°æ–°çš„è§‚ç‚¹å’Œç†è§£ï¼Œä»è€Œæ›´å¥½åœ°åº”å¯¹ä¸æ–­å˜åŒ–çš„ä¸–ç•Œå’ŒæŒ‘æˆ˜ã€‚
```

# <span id="Benchmark">Benchmark ç»“æœ/Benchmark Evaluation</span>

æˆ‘ä»¬åœ¨[é€šç”¨]ã€[æ³•å¾‹]ã€[åŒ»ç–—]ã€[æ•°å­¦]ã€[ä»£ç ]å’Œ[å¤šè¯­è¨€ç¿»è¯‘]å…­ä¸ªé¢†åŸŸçš„ä¸­è‹±æ–‡æƒå¨æ•°æ®é›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œäº†å¹¿æ³›æµ‹è¯•ï¼Œæ›´å¤šè¯¦ç»†æµ‹è¯„ç»“æœå¯æŸ¥çœ‹[GitHub]ã€‚

We have extensively tested the model on authoritative Chinese-English datasets across six domains: [General](https://github.com/baichuan-inc/Baichuan2/blob/main/README_EN.md#general-domain), [Legal](https://github.com/baichuan-inc/Baichuan2/blob/main/README_EN.md#law-and-medicine), [Medical](https://github.com/baichuan-inc/Baichuan2/blob/main/README_EN.md#law-and-medicine), [Mathematics](https://github.com/baichuan-inc/Baichuan2/blob/main/README_EN.md#mathematics-and-code), [Code](https://github.com/baichuan-inc/Baichuan2/blob/main/README_EN.md#mathematics-and-code), and [Multilingual Translation](https://github.com/baichuan-inc/Baichuan2/blob/main/README_EN.md#multilingual-translation). For more detailed evaluation results, please refer to [GitHub](https://github.com/baichuan-inc/Baichuan2/blob/main/README_EN.md).

### 7B Model Results

|                         | **C-Eval** | **MMLU** | **CMMLU** | **Gaokao** | **AGIEval** | **BBH** |
|:-----------------------:|:----------:|:--------:|:---------:|:----------:|:-----------:|:-------:|
|                         |  5-shot    |  5-shot  |  5-shot   | 5-shot     | 5-shot      | 3-shot  |
|        **GPT-4**        | 68.40      | 83.93    | 70.33     | 66.15      | 63.27       | 75.12   |
|    **GPT-3.5 Turbo**    | 51.10      | 68.54    | 54.06     | 47.07      | 46.13       | 61.59   |
|      **LLaMA-7B**       | 27.10      | 35.10    | 26.75     | 27.81      | 28.17       | 32.38   |
|      **LLaMA2-7B**      | 28.90      | 45.73    | 31.38     | 25.97      | 26.53       | 39.16   |
|       **MPT-7B**        | 27.15      | 27.93    | 26.00     | 26.54      | 24.83       | 35.20   |
|      **Falcon-7B**      | 24.23      | 26.03    | 25.66     | 24.24      | 24.10       | 28.77   |
|     **ChatGLM2-6B**     | 50.20      | 45.90    | 49.00     | 49.44      | 45.28       | 31.65   |
|    **[Baichuan-7B]**    | 42.80      | 42.30    | 44.02     | 36.34      | 34.44       | 32.48   |
| **[Baichuan2-7B-Base]** | 54.00      | 54.16    | 57.07     | 47.47      | 42.73       | 41.56   |

### 13B Model Results

|                             | **C-Eval** | **MMLU** | **CMMLU** | **Gaokao** | **AGIEval** | **BBH** |
|:---------------------------:|:----------:|:--------:|:---------:|:----------:|:-----------:|:-------:|
|                             |  5-shot    |  5-shot  |  5-shot   | 5-shot     | 5-shot      | 3-shot  |
|          **GPT-4**          | 68.40      | 83.93    | 70.33     | 66.15      | 63.27       | 75.12   |
|      **GPT-3.5 Turbo**      | 51.10      | 68.54    | 54.06     | 47.07      | 46.13       | 61.59   |
|        **LLaMA-13B**        | 28.50      | 46.30    | 31.15     | 28.23      | 28.22       | 37.89   |
|       **LLaMA2-13B**        | 35.80      | 55.09    | 37.99     | 30.83      | 32.29       | 46.98   |
|       **Vicuna-13B**        | 32.80      | 52.00    | 36.28     | 30.11      | 31.55       | 43.04   |
| **Chinese-Alpaca-Plus-13B** | 38.80      | 43.90    | 33.43     | 34.78      | 35.46       | 28.94   |
|       **XVERSE-13B**        | 53.70      | 55.21    | 58.44     | 44.69      | 42.54       | 38.06   |
|   **[Baichuan-13B-Base]**    | 52.40      | 51.60    | 55.30     | 49.69      | 43.20       | 43.01   |
|  **[Baichuan2-13B-Base]**   | 58.10      | 59.17    | 61.97     | 54.33      | 48.17       | 48.78   |

## è®­ç»ƒè¿‡ç¨‹æ¨¡å‹/Training Dynamics

é™¤äº†è®­ç»ƒäº† 2.6 ä¸‡äº¿ Tokens çš„ [Baichuan2-7B-Base](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base) æ¨¡å‹ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†åœ¨æ­¤ä¹‹å‰çš„å¦å¤– 11 ä¸ªä¸­é—´è¿‡ç¨‹çš„æ¨¡å‹ï¼ˆåˆ†åˆ«å¯¹åº”è®­ç»ƒäº†çº¦ 0.2 ~ 2.4 ä¸‡äº¿ Tokensï¼‰ä¾›ç¤¾åŒºç ”ç©¶ä½¿ç”¨
ï¼ˆ[è®­ç»ƒè¿‡ç¨‹checkpointä¸‹è½½](https://huggingface.co/baichuan-inc/Baichuan2-7B-Intermediate-Checkpoints)ï¼‰ã€‚ä¸‹å›¾ç»™å‡ºäº†è¿™äº› checkpoints åœ¨ C-Evalã€MMLUã€CMMLU ä¸‰ä¸ª benchmark ä¸Šçš„æ•ˆæœå˜åŒ–ï¼š

In addition to the [Baichuan2-7B-Base](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base) model trained on 2.6 trillion tokens, we also offer 11 additional intermediate-stage models for community research, corresponding to training on approximately 0.2 to 2.4 trillion tokens each ([Intermediate Checkpoints Download](https://huggingface.co/baichuan-inc/Baichuan2-7B-Intermediate-Checkpoints)). The graph below shows the performance changes of these checkpoints on three benchmarks: C-Eval, MMLU, and CMMLU.

![checkpoint](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/resolve/main/checkpoints.jpeg)

# <span id="Community">ç¤¾åŒºä¸ç”Ÿæ€/Community</span>

## Intel é…·ç¿ Ultra å¹³å°è¿è¡Œç™¾å·å¤§æ¨¡å‹

ä½¿ç”¨é…·ç¿â„¢/è‡³å¼ºÂ® å¯æ‰©å±•å¤„ç†å™¨æˆ–é…åˆé”ç‚«â„¢ GPUç­‰è¿›è¡Œéƒ¨ç½²[Baichuan2-7B-Chat]ï¼Œ[Baichuan2-13B-Chat]æ¨¡å‹ï¼Œæ¨èä½¿ç”¨ BigDL-LLM([CPU], [GPU])ä»¥å‘æŒ¥æ›´å¥½æ¨ç†æ€§èƒ½ã€‚

è¯¦ç»†æ”¯æŒä¿¡æ¯å¯å‚è€ƒ[ä¸­æ–‡æ“ä½œæ‰‹å†Œ](https://github.com/intel-analytics/bigdl-llm-tutorial/tree/main/Chinese_Version)ï¼ŒåŒ…æ‹¬ç”¨notebookæ”¯æŒï¼Œ[åŠ è½½ï¼Œä¼˜åŒ–ï¼Œä¿å­˜æ–¹æ³•](https://github.com/intel-analytics/bigdl-llm-tutorial/blob/main/Chinese_Version/ch_3_AppDev_Basic/3_BasicApp.ipynb)ç­‰ã€‚

When deploy on Coreâ„¢/XeonÂ® Scalable Processors or with Arcâ„¢ GPU, BigDL-LLM ([CPU], [GPU]) is recommended to take full advantage of better inference performance.

# <span id="Terms">å£°æ˜ä¸åè®®/Terms and Conditions</span>

## å£°æ˜

æˆ‘ä»¬åœ¨æ­¤å£°æ˜ï¼Œæˆ‘ä»¬çš„å¼€å‘å›¢é˜Ÿå¹¶æœªåŸºäº Baichuan 2 æ¨¡å‹å¼€å‘ä»»ä½•åº”ç”¨ï¼Œæ— è®ºæ˜¯åœ¨ iOSã€Androidã€ç½‘é¡µæˆ–ä»»ä½•å…¶ä»–å¹³å°ã€‚æˆ‘ä»¬å¼ºçƒˆå‘¼åæ‰€æœ‰ä½¿ç”¨è€…ï¼Œä¸è¦åˆ©ç”¨
Baichuan 2 æ¨¡å‹è¿›è¡Œä»»ä½•å±å®³å›½å®¶ç¤¾ä¼šå®‰å…¨æˆ–è¿æ³•çš„æ´»åŠ¨ã€‚å¦å¤–ï¼Œæˆ‘ä»¬ä¹Ÿè¦æ±‚ä½¿ç”¨è€…ä¸è¦å°† Baichuan 2
æ¨¡å‹ç”¨äºæœªç»é€‚å½“å®‰å…¨å®¡æŸ¥å’Œå¤‡æ¡ˆçš„äº’è”ç½‘æœåŠ¡ã€‚æˆ‘ä»¬å¸Œæœ›æ‰€æœ‰çš„ä½¿ç”¨è€…éƒ½èƒ½éµå®ˆè¿™ä¸ªåŸåˆ™ï¼Œç¡®ä¿ç§‘æŠ€çš„å‘å±•èƒ½åœ¨è§„èŒƒå’Œåˆæ³•çš„ç¯å¢ƒä¸‹è¿›è¡Œã€‚

æˆ‘ä»¬å·²ç»å°½æˆ‘ä»¬æ‰€èƒ½ï¼Œæ¥ç¡®ä¿æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ•°æ®çš„åˆè§„æ€§ã€‚ç„¶è€Œï¼Œå°½ç®¡æˆ‘ä»¬å·²ç»åšå‡ºäº†å·¨å¤§çš„åŠªåŠ›ï¼Œä½†ç”±äºæ¨¡å‹å’Œæ•°æ®çš„å¤æ‚æ€§ï¼Œä»æœ‰å¯èƒ½å­˜åœ¨ä¸€äº›æ— æ³•é¢„è§çš„é—®é¢˜ã€‚å› æ­¤ï¼Œå¦‚æœç”±äºä½¿ç”¨
Baichuan 2 å¼€æºæ¨¡å‹è€Œå¯¼è‡´çš„ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€å…¬å…±èˆ†è®ºé£é™©ï¼Œæˆ–æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨æ‰€å¸¦æ¥çš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚

We hereby declare that our team has not developed any applications based on Baichuan 2 models, not on iOS, Android, the web, or any other platform. We strongly call on all users not to use Baichuan 2 models for any activities that harm national / social security or violate the law. Also, we ask users not to use Baichuan 2 models for Internet services that have not undergone appropriate security reviews and filings. We hope that all users can abide by this principle and ensure that the development of technology proceeds in a regulated and legal environment.

We have done our best to ensure the compliance of the data used in the model training process. However, despite our considerable efforts, there may still be some unforeseeable issues due to the complexity of the model and data. Therefore, if any problems arise due to the use of Baichuan 2 open-source models, including but not limited to data security issues, public opinion risks, or any risks and problems brought about by the model being misled, abused, spread or improperly exploited, we will not assume any responsibility.

## åè®®

ç¤¾åŒºä½¿ç”¨ Baichuan 2 æ¨¡å‹éœ€è¦éµå¾ª [Apache 2.0](https://github.com/baichuan-inc/Baichuan2/blob/main/LICENSE) å’Œ[ã€ŠBaichuan 2 æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/resolve/main/Baichuan%202%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf)ã€‚Baichuan 2 æ¨¡å‹æ”¯æŒå•†ä¸šç”¨é€”ï¼Œå¦‚æœæ‚¨è®¡åˆ’å°† Baichuan 2 æ¨¡å‹æˆ–å…¶è¡ç”Ÿå“ç”¨äºå•†ä¸šç›®çš„ï¼Œè¯·æ‚¨ç¡®è®¤æ‚¨çš„ä¸»ä½“ç¬¦åˆä»¥ä¸‹æƒ…å†µï¼š
  1. æ‚¨æˆ–æ‚¨çš„å…³è”æ–¹çš„æœåŠ¡æˆ–äº§å“çš„æ—¥å‡ç”¨æˆ·æ´»è·ƒé‡ï¼ˆDAUï¼‰ä½äº100ä¸‡ã€‚
  2. æ‚¨æˆ–æ‚¨çš„å…³è”æ–¹ä¸æ˜¯è½¯ä»¶æœåŠ¡æä¾›å•†ã€äº‘æœåŠ¡æä¾›å•†ã€‚
  3. æ‚¨æˆ–æ‚¨çš„å…³è”æ–¹ä¸å­˜åœ¨å°†æˆäºˆæ‚¨çš„å•†ç”¨è®¸å¯ï¼Œæœªç»ç™¾å·è®¸å¯äºŒæ¬¡æˆæƒç»™å…¶ä»–ç¬¬ä¸‰æ–¹çš„å¯èƒ½ã€‚

åœ¨ç¬¦åˆä»¥ä¸Šæ¡ä»¶çš„å‰æä¸‹ï¼Œæ‚¨éœ€è¦é€šè¿‡ä»¥ä¸‹è”ç³»é‚®ç®± opensource@baichuan-inc.com ï¼Œæäº¤ã€ŠBaichuan 2 æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹è¦æ±‚çš„ç”³è¯·ææ–™ã€‚å®¡æ ¸é€šè¿‡åï¼Œç™¾å·å°†ç‰¹æ­¤æˆäºˆæ‚¨ä¸€ä¸ªéæ’ä»–æ€§ã€å…¨çƒæ€§ã€ä¸å¯è½¬è®©ã€ä¸å¯å†è®¸å¯ã€å¯æ’¤é”€çš„å•†ç”¨ç‰ˆæƒè®¸å¯ã€‚

The community usage of Baichuan 2 model requires adherence to [Apache 2.0](https://github.com/baichuan-inc/Baichuan2/blob/main/LICENSE) and [Community License for Baichuan2 Model](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/resolve/main/Baichuan%202%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf). The Baichuan 2 model supports commercial use. If you plan to use the Baichuan 2 model or its derivatives for commercial purposes, please ensure that your entity meets the following conditions:

  1. The Daily Active Users (DAU) of your or your affiliate's service or product is less than 1 million.
  2. Neither you nor your affiliates are software service providers or cloud service providers.
  3. There is no possibility for you or your affiliates to grant the commercial license given to you, to reauthorize it to other third parties without Baichuan's permission.

Upon meeting the above conditions, you need to submit the application materials required by the Baichuan 2 Model Community License Agreement via the following contact email: opensource@baichuan-inc.com. Once approved, Baichuan will hereby grant you a non-exclusive, global, non-transferable, non-sublicensable, revocable commercial copyright license.


[GitHub]:https://github.com/baichuan-inc/Baichuan2
[Baichuan2]:https://github.com/baichuan-inc/Baichuan2

[Baichuan-7B]:https://huggingface.co/baichuan-inc/Baichuan-7B
[Baichuan2-7B-Base]:https://huggingface.co/baichuan-inc/Baichuan2-7B-Base
[Baichuan2-7B-Chat]:https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat
[Baichuan2-7B-Chat-4bits]:https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat-4bits
[Baichuan-13B-Base]:https://huggingface.co/baichuan-inc/Baichuan-13B-Base
[Baichuan2-13B-Base]:https://huggingface.co/baichuan-inc/Baichuan2-13B-Base
[Baichuan2-13B-Chat]:https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat
[Baichuan2-13B-Chat-4bits]:https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat-4bits

[é€šç”¨]:https://github.com/baichuan-inc/Baichuan2#%E9%80%9A%E7%94%A8%E9%A2%86%E5%9F%9F
[æ³•å¾‹]:https://github.com/baichuan-inc/Baichuan2#%E6%B3%95%E5%BE%8B%E5%8C%BB%E7%96%97
[åŒ»ç–—]:https://github.com/baichuan-inc/Baichuan2#%E6%B3%95%E5%BE%8B%E5%8C%BB%E7%96%97
[æ•°å­¦]:https://github.com/baichuan-inc/Baichuan2#%E6%95%B0%E5%AD%A6%E4%BB%A3%E7%A0%81
[ä»£ç ]:https://github.com/baichuan-inc/Baichuan2#%E6%95%B0%E5%AD%A6%E4%BB%A3%E7%A0%81
[å¤šè¯­è¨€ç¿»è¯‘]:https://github.com/baichuan-inc/Baichuan2#%E5%A4%9A%E8%AF%AD%E8%A8%80%E7%BF%BB%E8%AF%91

[ã€ŠBaichuan 2 æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹]:https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/blob/main/Baichuan%202%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf

[é‚®ä»¶ç”³è¯·]: mailto:opensource@baichuan-inc.com
[Email]: mailto:opensource@baichuan-inc.com
[opensource@baichuan-inc.com]: mailto:opensource@baichuan-inc.com
[è®­ç»ƒè¿‡ç¨‹heckpointä¸‹è½½]: https://huggingface.co/baichuan-inc/Baichuan2-7B-Intermediate-Checkpoints
[ç™¾å·æ™ºèƒ½]: https://www.baichuan-ai.com

[CPU]: https://github.com/intel-analytics/BigDL/tree/main/python/llm/example/CPU/HF-Transformers-AutoModels/Model/baichuan2
[GPU]: https://github.com/intel-analytics/BigDL/tree/main/python/llm/example/GPU/HF-Transformers-AutoModels/Model/baichuan2
